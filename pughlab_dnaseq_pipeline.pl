#!/usr/bin/env perl
### pughlab_dnaseq_pipeline.pl #####################################################################
use AutoLoader 'AUTOLOAD';
use strict;
use warnings;
use Carp;
use POSIX qw(strftime);
use Getopt::Std;
use Getopt::Long;
use File::Basename;
use File::Path qw(make_path);
use YAML qw(LoadFile);

my $cwd = dirname($0);
require "$cwd/scripts/utilities.pl";

####################################################################################################
# version       author	  	comment
# 1.0		sprokopec       script to run PughLab DNASeq pipeline

### USAGE ##########################################################################################
# pughlab_dnaseq_pipeline.pl -c tool_config.yaml -d data.yaml
#
# where:
#	- tool_config.yaml contains tool versions and parameters, output directory, reference
#	information, etc.
#	- data_config.yaml contains sample information (YAML file containing paths to FASTQ files,
#	generated by create_fastq_yaml.pl)

### SUBROUTINES ####################################################################################

### MAIN ###########################################################################################
sub main {
	my %args = (
		tool_config	=> undef,
		data_config	=> undef,
		@_
		);

	my $tool_config = $args{tool_config};
	my $data_config = $args{data_config};

	### PREAMBLE ######################################################################################

	# load tool config
	my $tool_data_orig = LoadFile($tool_config);
	my $tool_data = error_checking(tool_data => $tool_data_orig);
	my $date = strftime "%F", localtime;
	my $timestamp = strftime "%F_%H-%M-%S", localtime;

	# check for and/or create output directories
	my $output_directory = $tool_data->{output_dir};
	$output_directory =~ s/\/$//;
	my $log_directory = join('/', $output_directory, 'logs', 'run_DNA_pipeline_' . $timestamp);

	unless(-e $output_directory) { make_path($output_directory); }
	unless(-e $log_directory) { make_path($log_directory); }

	# start logging
	my $log_file = join('/', $log_directory, 'run_DNASeq_pipeline.log');
	open (my $log, '>', $log_file) or die "Could not open $log_file for writing.";

	print $log "---\n";
	print $log "Running PughLab DNA-Seq pipeline.\n";
	print $log "\n  Tool config used: $tool_config";
	print $log "\n    Output directory: $output_directory";
	print $log "\n  Sample config used: $data_config";
	print $log "\n---\n\n";

	### MAIN ###########################################################################################

	my ($bwa_run_id, $gatk_run_id, $contest_run_id, $coverage_run_id, $hc_run_id) = '';
	my ($mutect_run_id, $mutect2_run_id, $varscan_run_id, $sequenza_run_id, $delly_run_id) = '';

	# prepare directory structure
	my $bwa_directory = join('/', $output_directory, 'BWA');
	my $gatk_directory = join('/', $output_directory, 'GATK');
	my $contest_directory = join('/', $output_directory, 'BAMQC', 'ContEst');
	my $coverage_directory = join('/', $output_directory, 'BAMQC', 'Coverage');
	my $hc_directory = join('/', $output_directory, 'HaplotypeCaller');
	my $mutect_directory = join('/', $output_directory, 'MuTect');
	my $mutect2_directory = join('/', $output_directory, 'MuTect2');
	my $varscan_directory = join('/', $output_directory, 'VarScan');
	my $sequenza_directory = join('/', $output_directory, 'Sequenza');
	my $delly_directory = join('/', $output_directory, 'Delly');

	# indicate YAML files for processed BAMs
	my $bwa_output_yaml = join('/', $bwa_directory, 'bwa_bam_config.yaml');
	my $gatk_output_yaml = join('/', $gatk_directory, 'gatk_bam_config.yaml');

	# Should pre-processing (alignment + GATK indel realignment/recalibration + QC) be performed?
	if ('Y' eq $tool_data->{preprocessing}->{run}) {

		## run BWA-alignment pipeline
		unless(-e $bwa_directory) { make_path($bwa_directory); }

		if (defined($tool_data->{preprocessing}->{bwa_config})) {

			my $bwa_command = join(' ',
				"perl $cwd/scripts/bwa.pl",
				"-o", $bwa_directory,
				"-t", $tool_data->{preprocessing}->{bwa_config},
				"-d", $data_config,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run}
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for bwa.pl\n";
			print $log "  COMMAND: $bwa_command\n\n";

			$bwa_run_id = `$bwa_command`;
			sleep(5);

			print $log ">>> Final BWA job id: $bwa_run_id\n\n";

			}

		## run GATK indel realignment/recalibration pipeline
		unless(-e $gatk_directory) { make_path($gatk_directory); }

		if (defined($tool_data->{preprocessing}->{gatk_config})) {

			my $gatk_command = join(' ',
				"perl $cwd/scripts/gatk.pl",
				"--dna",
				"-o", $gatk_directory,
				"-t", $tool_data->{preprocessing}->{gatk_config},
				"-d", $bwa_output_yaml,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run},
				"--depends", $bwa_run_id
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for gatk.pl\n";
			print $log "  COMMAND: $gatk_command\n\n";

			$gatk_run_id = `$gatk_command`;
			sleep(5);

			print $log ">>> Final GATK job id: $gatk_run_id\n\n";

			}

		## run GATK's ContEst for contamination estimation (T/N only)
		## and GATK's DepthOfCoverage and find Callable Bases
		unless(-e $contest_directory) { make_path($contest_directory); }
		unless(-e $coverage_directory) { make_path($coverage_directory); }

		if (defined($tool_data->{preprocessing}->{bamqc_config})) {

			my $contest_command = join(' ',
				"perl $cwd/scripts/contest.pl",
				"-o", $contest_directory,
				"-t", $tool_data->{preprocessing}->{bamqc_config},
				"-d", $gatk_output_yaml,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run},
				"--depends", $gatk_run_id
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for contest.pl\n";
			print $log "  COMMAND: $contest_command\n\n";

			$contest_run_id = `$contest_command`;
			sleep(5);

			print $log ">>> Final ContEst job id: $contest_run_id\n\n";

			my $coverage_command = join(' ',
				"perl $cwd/scripts/get_coverage.pl",
				"-o", $coverage_directory,
				"-t", $tool_data->{preprocessing}->{bamqc_config},
				"-d", $gatk_output_yaml,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run},
				"--depends", $gatk_run_id
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for get_coverage.pl\n";
			print $log "  COMMAND: $coverage_command\n\n";

			$coverage_run_id = `$coverage_command`;
			sleep(5);

			print $log ">>> Final ContEst job id: $coverage_run_id\n\n";
			}
		}

	########################################################################################
	# From here on out, it makes more sense to run everything as a single batch.
	########################################################################################
	if ('Y' eq $tool_data->{variant_calling}->{run}) {

		## run GATK's HaplotypeCaller pipeline
		if (defined($tool_data->{variant_calling}->{haplotype_caller_config})) {
	 
			my $hc_command = join(' ',
				"perl $cwd/scripts/haplotype_caller.pl",
				"--dna",
				"-o", $hc_directory,
				"-t", $tool_data->{variant_calling}->{haplotype_caller_config},
				"-d", $gatk_output_yaml,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run},
				"--depends", $gatk_run_id
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for haplotype_caller.pl\n";
			print $log "  COMMAND: $hc_command\n\n";

			$hc_run_id = `$hc_command`;
			sleep(5);

			print $log ">>> Final HaplotypeCaller job id: $hc_run_id\n\n";

			# next step will run Genotype GVCFs, and filter final output
			$hc_command = join(' ',
				"perl $cwd/scripts/genotype_gvcfs.pl",
				"-o", $hc_directory,
				"-t", $tool_data->{variant_calling}->{haplotype_caller_config},
				"-d", $gatk_output_yaml,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run},
				"--depends", $hc_run_id
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for genotype_gvcfs.pl\n";
			print $log "  COMMAND: $hc_command\n\n";
		
			$hc_run_id = `$hc_command`;
			sleep(5);
			}

		## run GATK's MuTect pipeline
		if (defined($tool_data->{variant_calling}->{mutect_config})) {

			unless(-e $mutect_directory) { make_path($mutect_directory); }

			# first create a panel of normals
			my $mutect_command = join(' ',
				"perl $cwd/scripts/mutect.pl",
				"-o", join('/', $mutect_directory, 'PanelOfNormals'),
				"-t", $tool_data->{variant_calling}->{mutect_config},
				"-d", $gatk_output_yaml,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run},
				"--depends", $gatk_run_id,
				"--create-panel-of-normals"
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for mutect.pl --create-panel-of-normals\n";
			print $log "  COMMAND: $mutect_command\n\n";

			$mutect_run_id = `$mutect_command`;
			sleep(5);
			
			print $log ">>> Final MuTect PoN job id: $mutect_run_id\n\n";

			# next run variant calling
			$mutect_command = join(' ',
				"perl $cwd/scripts/mutect.pl",
				"-o", $mutect_directory,
				"-t", $tool_data->{variant_calling}->{mutect_config},
				"-d", $gatk_output_yaml,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run},
				"--pon", join('/', $mutect_directory, 'panel_of_normals.vcf'),
				"--depends", $mutect_run_id
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for mutect.pl\n";
			print $log "  COMMAND: $mutect_command\n\n";

			$mutect_run_id = `$mutect_command`;
			sleep(5);
			}

		## also run GATK's newer MuTect2 pipeline
		if (defined($tool_data->{variant_calling}->{mutect2_config})) {

			unless(-e $mutect2_directory) { make_path($mutect2_directory); }

			# first create a panel of normals
			my $mutect2_command = join(' ',
				"perl $cwd/scripts/mutect2.pl",
				"-o", join('/', $mutect2_directory, 'PanelOfNormals'),
				"-t", $tool_data->{variant_calling}->{mutect2_config},
				"-d", $gatk_output_yaml,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run},
				"--depends", $gatk_run_id,
				"--create-panel-of-normals"
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for mutect2.pl --create-panel-of-normals\n";
			print $log "  COMMAND: $mutect2_command\n\n";

			$mutect2_run_id = `$mutect2_command`;
			sleep(5);
			
			print $log ">>> Final MuTect2 PoN job id: $mutect2_run_id\n\n";

			# now run the actual somatic variant calling
			$mutect2_command = join(' ',
				"perl $cwd/scripts/mutect2.pl",
				"-o", $mutect2_directory,
				"-t", $tool_data->{variant_calling}->{mutect2_config},
				"-d", $gatk_output_yaml,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run},
				"--pon", join('/', $mutect2_directory, 'panel_of_normals.vcf'),
				"--depends", $mutect2_run_id
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for mutect2.pl\n";
			print $log "  COMMAND: $mutect2_command\n\n";

			$mutect2_run_id = `$mutect2_command`;
			sleep(5);
			}

		## run VarScan SNV/CNV pipeline
		if (defined($tool_data->{variant_calling}->{varscan_config})) {

			unless(-e $varscan_directory) { make_path($varscan_directory); }

			# first run T/N pairs -- this will call germline variants for use in filtering T-only callsets
			my $varscan_command = join(' ',
				"perl $cwd/scripts/varscan.pl",
				"-o", $varscan_directory,
				"-t", $tool_data->{variant_calling}->{varscan_config},
				"-d", $gatk_output_yaml,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run},
				"--mode paired",
				"--depends", $gatk_run_id
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for varscan.pl (T/N mode)\n";
			print $log "  COMMAND: $varscan_command\n\n";

			$varscan_run_id = `$varscan_command`;
			sleep(5);
			
			print $log ">>> Final VarScan T/N job id: $varscan_run_id\n\n";

			# now run on T-only, using germline variants from T/N pairs to filter
			$varscan_command = join(' ',
				"perl $cwd/scripts/varscan.pl",
				"-o", $varscan_directory,
				"-t", $tool_data->{variant_calling}->{varscan_config},
				"-d", $gatk_output_yaml,
				"-h", $tool_data->{HPC_driver},
				"-r", $tool_data->{del_intermediates},
				"-n", $tool_data->{dry_run},
				"--mode unpaired",
				"--pon", join('/', $varscan_directory, 'panel_of_normals.vcf'),
				"--depends", $varscan_run_id
				);

			# record command (in log directory) and then run job
			print $log "Submitting job for varscan.pl\n";
			print $log "  COMMAND: $varscan_command\n\n";

			$varscan_run_id = `$varscan_command`;
			sleep(5);
			
			print $log ">>> Final VarScan job id: $varscan_run_id\n\n";
			}
		}

	## run Sequenza pipeline
	if (defined($tool_data->{variant_calling}->{sequenza_config})) {

		unless(-e $sequenza_directory) { make_path($sequenza_directory); }

		my $sequenza_command = join(' ',
			"perl $cwd/scripts/sequenza.pl",
			"-o", $sequenza_directory,
			"-t", $tool_data->{variant_calling}->{sequenza_config},
			"-d", $gatk_output_yaml,
			"-h", $tool_data->{HPC_driver},
			"-r", $tool_data->{del_intermediates},
			"-n", $tool_data->{dry_run},
			"--depends", $varscan_run_id
			);

		# record command (in log directory) and then run job
		print $log "Submitting job for sequenza.pl\n";
		print $log "  COMMAND: $sequenza_command\n\n";

		$sequenza_run_id = `$sequenza_command`;
		sleep(5);

		}

	## run Delly SV pipeline
	if (defined($tool_data->{variant_calling}->{delly_config})) {

		unless(-e $delly_directory) { make_path($delly_directory); }

		my $delly_command = join(' ',
			"perl $cwd/scripts/delly.pl",
			"-o", $delly_directory,
			"-t", $tool_data->{variant_calling}->{delly_config},
			"-d", $gatk_output_yaml,
			"-h", $tool_data->{HPC_driver},
			"-r", $tool_data->{del_intermediates},
			"-n", $tool_data->{dry_run},
			"--depends", $gatk_run_id
			);

		# record command (in log directory) and then run job
		print $log "Submitting job for delly.pl\n";
		print $log "  COMMAND: $delly_command\n\n";

		$delly_run_id = `$delly_command`;
		sleep(5);

		}

	# finish up
	print $log "\nProgramming terminated successfully.\n\n";
	close $log;

	}

### GETOPTS AND DEFAULT VALUES #####################################################################
# declare variables
my $tool_config;
my $data_config;

# read in command line arguments
GetOptions(
	'c|config=s'	=> \$tool_config,
	'd|data=s'	=> \$data_config
	 );

if (!defined($tool_config)) { die("No tool config file defined; please provide -c | --config (ie, tool_config.yaml)"); }
if (!defined($data_config)) { die("No data config file defined; please provide -d | --data (ie, sample_config.yaml)"); }

main(tool_config => $tool_config, data_config => $data_config);
