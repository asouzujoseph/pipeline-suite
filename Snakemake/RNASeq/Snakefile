####################################################################################################
### PughLab RNA-Seq Pipeline #######################################################################
####################################################################################################

### SET-UP REQUIREMENTS ############################################################################
# indicate required input parameters
configfile: "config.yaml"

# import required packages
import pandas as pd
import os
import datetime

# extract other details from config
project_dir = config["project_dir"]
ref_genome = config["ref_type"]

# format timestamp (used for differentiating runs)
date = datetime.datetime.now()

# define reference-based input paths
if ref_genome == "hg19":
    known_mills = "/cluster/tools/data/genomes/human/hg19/variantcallingdata/Mills_and_1000G_gold_standard.indels.hg19.vcf"
    known_1000G_indels = "/cluster/tools/data/genomes/human/hg19/variantcallingdata/1000G_phase1.indels.hg19.vcf"
    known_1000G_snps = "/cluster/tools/data/genomes/human/hg19/variantcallingdata/1000G_phase1.snps.high_confidence.hg19.vcf"
    dbsnp	= "/cluster/tools/data/genomes/human/hg19/variantcallingdata/dbsnp_138.hg19.vcf"
    ref_type	= "GRCh37"
    extra_args  = ""
else:
    known_mills = "/cluster/tools/data/genomes/human/hg38/hg38bundle/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz"
    known_1000G_indels = "/cluster/tools/data/genomes/human/hg38/hg38bundle/Homo_sapiens_assembly38.known_indels.vcf.gz"
    known_1000G_snps = "/cluster/tools/data/genomes/human/hg38/hg38bundle/1000G_phase1.snps.high_confidence.hg38.vcf.gz"
    dbsnp	= "/cluster/tools/data/genomes/human/hg38/hg38bundle/dbsnp_144.hg38.vcf.gz"
    ref_type	= "GRCh38"
    extra_args  = "--skip-conversion-grch37" 

# extract sample details
samples = pd.read_table(config["fastq_file"]).set_index("sample", drop = False)

# extract read1/read2 for input validation
def get_r1(wildcards):
    files = samples.read1[wildcards.sample]
    return files.split(',')

def get_r2(wildcards):
    files = samples.read2[wildcards.sample]
    return files.split(',')

# extract read1/read2 strings for input to STAR
def get_r1_string(wildcards):
    return samples.read1[wildcards.sample]

def get_r2_string(wildcards):
    return samples.read2[wildcards.sample]

# define function to generate readgroup for SAM/BAM header
def get_readgroup(wildcards):
    id = 'ID:' + samples.patient[wildcards.sample]
    smp = 'SM:' + wildcards.sample
    platform = 'PL:Illumina'
    lib = 'LB:' + samples.library[wildcards.sample]
    lane = 'PU:' + samples.lane[wildcards.sample]
    readgroup = [id, smp, platform, lib, lane]
    return "\t".join(readgroup)

### BEGIN PROCESSING ###############################################################################
# this indicates the expected *final* output files - required to ensure all steps are run
rule all:
    input:
        expand("{project_dir}/HaplotypeCaller/{sample}/{sample}_HaplotypeCaller_filtered_annotated.maf", sample = samples["sample"], project_dir = project_dir),
        expand("{project_dir}/RSEM/{sample}/{sample}.genes.results", sample = samples["sample"], project_dir = project_dir),
        expand("{project_dir}/STAR-Fusion/{sample}/star-fusion.fusion_predictions.abridged.tsv", sample = samples["sample"], project_dir = project_dir),
        expand("{project_dir}/FusionCatcher/{sample}/final-list_candidate-fusion-genes.txt", sample = samples["sample"], project_dir = project_dir)

### run STAR aligner
rule runSTAR:
    input:
        ref = config["star_ref"],
        r1 = get_r1,
        r2 = get_r2
    params:
        runtime = "72:00:00",
        mem = config["star_mem"],
	extra_slurm_args = "-p all",
        tool = config["star_version"],
        readgroup = get_readgroup,
        r1 = get_r1_string,
        r2 = get_r2_string,
	jobname = "run_STAR_aligner_{sample}",
        out_dir = "{project_dir}/STAR/{sample}",
        tmp_dir = "{project_dir}/STAR/{sample}/TEMP"
    output:
        genome_bam = "{project_dir}/STAR/{sample}/Aligned.sortedByCoord.out.bam",
        transcriptome_bam = "{project_dir}/STAR/{sample}/Aligned.toTranscriptome.out.bam",
        chimeric = "{project_dir}/STAR/{sample}/Chimeric.out.junction"
    threads: 1
    shell:
     """
     module load {params.tool}

     cd {params.out_dir}

     STAR --runMode alignReads \
     --genomeDir {input.ref} \
     --readFilesCommand zcat \
     --readFilesIn {params.r1} {params.r2} \
     --twopassMode Basic \
     --outTmpDir {params.tmp_dir} \
     --outSAMtype BAM SortedByCoordinate --outSAMunmapped Within --outSAMprimaryFlag AllBestScore \
     --outBAMsortingThreadN 1 --outFilterIntronMotifs RemoveNoncanonical --chimSegmentMin 10 --chimJunctionOverhangMin 10 \
     --chimOutJunctionFormat 1 --alignSJDBoverhangMin 10 --alignMatesGapMax 100000 --alignIntronMax 100000 \
     --alignSJstitchMismatchNmax 5 -1 5 5 --chimMultimapScoreRange 3 --chimScoreJunctionNonGTAG -4 --chimMultimapNmax 20 \
     --outSAMattrRGline {params.readgroup} \
     --chimNonchimScoreDropMin 10 --peOverlapNbasesMin 12 --peOverlapMMp 0.1 --quantMode GeneCounts TranscriptomeSAM \
     --limitIObufferSize 250000000 --limitBAMsortRAM 29000000000

     if [ -s {output.genome_bam} ]; then
       rm -rf {params.tmp_dir}
     fi
     """

### run FusionCatcher
rule runFUSIONCATCHER:
    input:
        r1 = get_r1,
        r2 = get_r2
    params:
        runtime = "72:00:00",
        mem = config["fusioncatcher_mem"],
	extra_slurm_args = "-p himem",
        tool = config["fusioncatcher_version"],
        r1 = get_r1_string,
        r2 = get_r2_string,
	jobname = "run_FusionCatcher_{sample}",
        out_dir = "{project_dir}/FusionCatcher/{sample}",
        tmp_dir = "{project_dir}/FusionCatcher/{sample}/TEMP",
	extra_args = extra_args
    output:
        fusions = "{project_dir}/FusionCatcher/{sample}/final-list_candidate-fusion-genes.txt"
    threads: 1
    shell:
     """
     module load {params.tool}

     cd {params.out_dir}

     fusioncatcher.py \
     -i {params.r1},{params.r2} \
     -o {params.out_dir} \
     --keep-viruses-alignments \
     --tmp={params.tmp_dir} \
     {params.extra_args}

     if [ -s {output.fusions} ]; then
       rm -rf {params.tmp_dir}
     fi
     """

### run MarkDuplicates 
rule runMarkDup:
    input:
        bam = "{project_dir}/STAR/{sample}/Aligned.sortedByCoord.out.bam"
    params:
        runtime = "24:00:00",
	mem = config["markdup_mem"],
	extra_slurm_args = "-p all",
        tool = config["picard_version"],
        jobname = "run_MarkDuplicates_{sample}",
	tmp_dir = "{project_dir}/STAR/{sample}/TEMP"
    output:
        bam = "{project_dir}/STAR/{sample}/{sample}_sorted_markdup.bam",
        metrics = "{project_dir}/STAR/{sample}/{sample}_sorted_markdup.bam.metrics"
    threads: 1
    shell:
     """
     module load {params.tool}

     java -Xmx6g -Djava.io.tmpdir={params.tmp_dir} -jar $picard_dir/picard.jar MarkDuplicates \
     INPUT={input.bam} \
     OUTPUT={output.bam} \
     METRICS_FILE={output.metrics} \
     ASSUME_SORTED=true CREATE_INDEX=true CREATE_MD5_FILE=true \
     MAX_RECORDS_IN_RAM=100000 VALIDATION_STRINGENCY=SILENT

     if [ -s {output.bam} ]; then
       rm -rf {params.tmp_dir}
     fi
     """

### run RSEM 
rule runRSEM:
    input:
        bam = "{project_dir}/STAR/{sample}/Aligned.toTranscriptome.out.bam"
    params:
        runtime = "24:00:00",
	mem = config["rsem_mem"],
	extra_slurm_args = "-p all",
        tool = config["rsem_version"],
        ref = config["rsem_ref"],
        strand = config["strandedness"],
        jobname = "run_RSEM_{sample}",
	out_dir = "{project_dir}/RSEM/{sample}",
	tmp_dir = "{project_dir}/RSEM/{sample}/TEMP"
    output:
        bam = temp("{project_dir}/RSEM/{sample}/{sample}.transcript.bam"),
        genes = "{project_dir}/RSEM/{sample}/{sample}.genes.results",
        genes_md5 = "{project_dir}/RSEM/{sample}/{sample}.genes.results.md5",
        isoforms = "{project_dir}/RSEM/{sample}/{sample}.isoforms.results",
        isoforms_md5 = "{project_dir}/RSEM/{sample}/{sample}.isoforms.results.md5"
    threads: 1
    shell:
     """
     module load {params.tool}
     module load perl

     cd {params.out_dir}

     rsem-calculate-expression \
     --paired-end --bam --estimate-rspd -p 8 \
     --temporary-folder {params.tmp_dir} \
     --strandedness {params.strand} \
     {input.bam} {params.ref} {wildcards.sample}

     if [ -s {output.genes} ] && [ -s {output.isoforms} ]; then
       md5sum {output.genes} > {output.genes}.md5
       md5sum {output.isoforms} > {output.isoforms}.md5
       rm -rf {params.tmp_dir};
     fi
     """

### run STAR-Fusion
rule runFusions:
    input:
        ref = config["starfusion_ref"],
        file = "{project_dir}/STAR/{sample}/Chimeric.out.junction"
    params:
        runtime = "24:00:00",
	mem = config["starfusion_mem"],
	extra_slurm_args = "-p all",
        tool = config["starfusion_version"],
        star = config["star_version"],
        samtools = config["samtools_version"],
        jobname = "run_STAR-Fusion_{sample}",
	out_dir = "{project_dir}/STAR-Fusion/{sample}",
	tmp_dir = "{project_dir}/STAR-Fusion/{sample}/TEMP"
    output:
        fusions = "{project_dir}/STAR-Fusion/{sample}/star-fusion.fusion_predictions.abridged.tsv",
        fusions_md5 = "{project_dir}/STAR-Fusion/{sample}/star-fusion.fusion_predictions.abridged.tsv.md5"
    threads: 4
    shell:
     """
     module load perl
     module load {params.star}
     module load {params.samtools}
     module load tabix
     module load python

     cd {params.out_dir}

     {params.tool} \
     --genome_lib_dir {input.ref} \
     --chimeric_junction {input.file} \
     --output_dir {params.out_dir} \
     --CPU {threads} --tmpdir {params.tmp_dir}

     if [ -s {output.fusions} ]; then
       md5sum {output.fusions} > {output.fusions_md5};
       rm -rf {params.tmp_dir};
       rm -rf {params.out_dir}/pipeliner*;
       rm -rf {params.out_dir}/_starF_checkpoints;
       rm -rf {params.out_dir}/*.ok;
       tar -czvf star-fusion.preliminary.tar.gz {params.out_dir}/star-fusion.preliminary --remove-files;
     fi
     """

### run GATK indel realignment and base-quality score recalibration
rule runGATK:
    input:
        ref = config["gatk_ref"],
        bam = "{project_dir}/STAR/{sample}/{sample}_sorted_markdup.bam",
        known1 = known_1000G_indels,
        known2 = known_mills,
        known3 = known_1000G_snps,
        dbsnp = dbsnp
    params:
        runtime = "72:00:00",
	mem = config["gatk_mem"],
	java_mem = config["gatk_java_mem"],
	extra_slurm_args = "-p all",
        tool = config["gatk_version"],
        jobname = "run_GATK_{sample}",
	tmp_dir = "{project_dir}/GATK/{sample}/TEMP"
    output:
        split_bam = temp("{project_dir}/GATK/{sample}/{sample}_split.bam"),
        targets = "{project_dir}/GATK/{sample}/{sample}_target.intervals",
        realign_bam = temp("{project_dir}/GATK/{sample}/{sample}_split_realigned.bam"),
        bqsr = "{project_dir}/GATK/{sample}/{sample}.recal_data.grp",
        recal_bam = "{project_dir}/GATK/{sample}/{sample}_realigned_recalibrated.bam"
    threads: 1
    shell:
     """
     module load {params.tool}

     java -Xmx{params.java_mem} -Djava.io.tmpdir={params.tmp_dir} -jar $gatk_dir/GenomeAnalysisTK.jar -T SplitNCigarReads \
     -R {input.ref} \
     -I {input.bam} \
     -o {output.split_bam} \
     -rf ReassignOneMappingQuality -rf UnmappedRead -RMQF 255 -RMQT 60 -U ALLOW_N_CIGAR_READS \
     --generate_md5

     java -Xmx{params.java_mem} -Djava.io.tmpdir={params.tmp_dir} -jar $gatk_dir/GenomeAnalysisTK.jar -T RealignerTargetCreator \
     -R {input.ref} \
     -I {output.split_bam} \
     -o {output.targets} \
     -known {input.known1} \
     -known {input.known2}

     if [ -s {output.targets} ]; then
       md5sum {output.targets} > {output.targets}.md5
     fi

     java -Xmx{params.java_mem} -Djava.io.tmpdir={params.tmp_dir} -jar $gatk_dir/GenomeAnalysisTK.jar -T IndelRealigner \
     -R {input.ref} \
     -I {output.split_bam} \
     -targetIntervals {output.targets} \
     -o {output.realign_bam} \
     --generate_md5

     java -Xmx{params.java_mem} -Djava.io.tmpdir={params.tmp_dir} -jar $gatk_dir/GenomeAnalysisTK.jar -T BaseRecalibrator \
     -R {input.ref} \
     -I {output.realign_bam} \
     -knownSites {input.known3} \
     -knownSites {input.dbsnp} \
     -o {output.bqsr} 

     if [ -s {output.bqsr} ]; then
       md5sum {output.bqsr} > {output.bqsr}.md5
     fi

     java -Xmx{params.java_mem} -Djava.io.tmpdir={params.tmp_dir} -jar $gatk_dir/GenomeAnalysisTK.jar -T PrintReads \
     -R {input.ref} \
     -I {output.realign_bam} \
     -BQSR {output.bqsr} \
     -o {output.recal_bam} \
     --generate_md5

     if [ -s {output.recal_bam}.md5 ]; then
       rm -rf {params.tmp_dir}
     fi
     """

### run GATK's HaplotypeCaller
rule runHaplotypeCaller:
    input:
        ref = config["gatk_ref"],
        bam = "{project_dir}/GATK/{sample}/{sample}_realigned_recalibrated.bam"
    params:
        runtime = "72:00:00",
	mem = config["haplotype_mem"],
	java_mem = config["haplotype_java_mem"],
	extra_slurm_args = "-p all",
        tool = config["gatk_version"],
        jobname = "run_HaplotypeCaller_{sample}",
        tmp_dir = "{project_dir}/HaplotypeCaller/{sample}/TEMP"
    output:
        full_vcf = temp("{project_dir}/HaplotypeCaller/{sample}/{sample}_HaplotypeCaller.vcf"),
        filtered_vcf = "{project_dir}/HaplotypeCaller/{sample}/{sample}_HaplotypeCaller_filtered.vcf",
        filtered_vcf_md5 = "{project_dir}/HaplotypeCaller/{sample}/{sample}_HaplotypeCaller_filtered.vcf.md5"
    threads: 1
    shell:
     """
     module load {params.tool}

     java -Xmx{params.java_mem} -Djava.io.tmpdir={params.tmp_dir} -jar $gatk_dir/GenomeAnalysisTK.jar -T HaplotypeCaller \
     -R {input.ref} \
     -I {input.bam} \
     -o {output.full_vcf} \
     -dontUseSoftClippedBases -stand_call_conf 20.0

     if [ -s {output.full_vcf} ]; then
       md5sum {output.full_vcf} > {output.full_vcf}.md5
     fi

     java -Xmx{params.java_mem} -Djava.io.tmpdir={params.tmp_dir} -jar $gatk_dir/GenomeAnalysisTK.jar -T VariantFiltration \
     -R {input.ref} \
     -V {output.full_vcf} \
     -window 35 -cluster 3 -filterName FS -filter "FS > 30.0" \
     -filterName QD -filter "QD < 2.0" \
     -o {output.filtered_vcf}

     if [ -s {output.filtered_vcf} ]; then
       md5sum {output.filtered_vcf} > {output.filtered_vcf}.md5
     fi
     """

### run vcf2maf (with VEP)
rule runVCF2MAF:
    input:
        ref = config["gatk_ref"],
        vcf = "{project_dir}/HaplotypeCaller/{sample}/{sample}_HaplotypeCaller_filtered.vcf",
        md5 = "{project_dir}/HaplotypeCaller/{sample}/{sample}_HaplotypeCaller_filtered.vcf.md5"
    params:
        runtime = "72:00:00",
	mem = config["vep_mem"],
	extra_slurm_args = "-p all",
        samtools = config["samtools_version"],
        ref_genome = ref_type,
        vcf2maf = config["vcf2maf"],
        vep = config["vep_path"],
        vep_data = config["vep_data"],
        vep_filter = config["vep_filter"],
        vep_vcf = temp("{project_dir}/HaplotypeCaller/{sample}/TEMP/{sample}_HaplotypeCaller_filtered.vep.vcf"),
        jobname = "run_VCF2MAF_haplotypecaller_{sample}",
        tmp_dir = "{project_dir}/HaplotypeCaller/{sample}/TEMP",
        annotated_vcf = "{project_dir}/HaplotypeCaller/{sample}/{sample}_HaplotypeCaller_filtered_annotated.vcf"
    output:
        annotated_maf = "{project_dir}/HaplotypeCaller/{sample}/{sample}_HaplotypeCaller_filtered_annotated.maf",
        maf_md5 = "{project_dir}/HaplotypeCaller/{sample}/{sample}_HaplotypeCaller_filtered_annotated.maf.md5"
    threads: 1
    shell:
     """
     module load perl
     module load {params.samtools}

     perl {params.vcf2maf} \
     --species homo_sapiens \
     --ncbi-build {params.ref_genome} \
     --ref-fasta {input.ref} \
     --input-vcf {input.vcf} \
     --output-maf {output.annotated_maf} \
     --tumor-id {wildcards.sample} \
     --vep-path {params.vep} \
     --vep-data {params.vep_data} \
     --vep-forks 1 \
     --filter-vcf {params.vep_filter} \
     --buffer-size 1000 \
     --tmp-dir {params.tmp_dir}

     if [ -s {output.annotated_maf} ]; then
       md5sum {output.annotated_maf} > {output.annotated_maf}.md5;
       mv {params.vep_vcf} {params.annotated_vcf};
       md5sum {params.annotated_vcf} > {params.annotated_vcf}.md5;
       gzip {params.annotated_vcf};
       rm -rf {params.tmp_dir};
     fi
     """
